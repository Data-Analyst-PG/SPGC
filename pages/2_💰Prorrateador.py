import streamlit as st
import pandas as pd
from io import BytesIO
from supabase import create_client, Client
from datetime import date

# --- CONFIGURACI√ìN SUPABASE ---
url = st.secrets["SUPABASE_URL"]
key = st.secrets["SUPABASE_KEY"]
supabase = create_client(url, key)

# ======================================================================================================
st.title("üßæProrrateo de Gastos Generales")

# ================================
# Subir archivo y generar resumen
# ================================

# Subir archivo Excel
uploaded_file = st.file_uploader("Sube el archivo con la hoja 'PASO 1'", type=["xlsx"])

if uploaded_file:
    try:
        # Leer hoja espec√≠fica
        df = pd.read_excel(uploaded_file, sheet_name="PASO 1")
        df.columns = df.columns.str.strip().str.upper()
        st.session_state["df_original"] = df 

        # Asegurar nombres consistentes
        df.columns = df.columns.str.strip().str.upper()

        # Filtrar "GASTO GENERAL"
        gasto_general = df[df["SUCURSAL"] == "GASTO GENERAL"]

        # Agrupar por AREA/GASTO y sumar los CARGOS
        resumen = (
            gasto_general
            .groupby("AREA/CUENTA", as_index=False)["CARGOS"]
            .sum()
            .sort_values(by="CARGOS", ascending=False)
        )

        # Guardar en session_state para el m√≥dulo 2
        st.session_state['resumen'] = resumen

        st.success("Resumen generado con √©xito.")
        st.dataframe(resumen, use_container_width=True)

        # Exportar a Excel
        def export_excel(df):
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                df.to_excel(writer, sheet_name="Resumen Gastos", index=False)
            return buffer.getvalue()

        st.download_button(
            "üì• Descargar resumen en Excel",
            data=export_excel(resumen),
            file_name="resumen_gastos_generales.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.error(f"Error procesando el archivo: {e}")

# ========================================
# Captura de Tr√°fico y Fecha por Sucursal
# ========================================

st.subheader("üöõ Captura de Tr√°fico por Sucursal")

# Lista fija de sucursales (precargadas)
sucursales = [
    "CAR-GAR", "CHICAGO", "CONSOLIDADO", "DALLAS", "GUADALAJARA",
    "LEON", "LINCOLN LOGISTICS", "MG HAULERS", "MONTERREY",
    "NUEVO LAREDO", "QUERETARO", "ROLANDO ALFARO"
]

# Fecha global que se aplicar√° a todos los registros
fecha_global = st.date_input("üìÖ Fecha de tr√°fico", value=date.today())

# Crear un DataFrame editable para capturar los n√∫meros de tr√°fico
traficos_df = pd.DataFrame({
    "Sucursal": sucursales,
    "Tr√°fico": ["" for _ in sucursales]
})

st.markdown("### ‚úèÔ∏è Captura los n√∫meros de tr√°fico")
edit_df = st.data_editor(
    traficos_df,
    use_container_width=True,
    num_rows="fixed",
    key="trafico_editor"
)

# Bot√≥n para guardar en Supabase
if st.button("üíæ Guardar en Supabase"):
    try:
        df_to_save = edit_df.copy()

        # Validaciones b√°sicas
        faltan = df_to_save["Tr√°fico"].astype(str).str.strip().eq("")
        if faltan.any():
            st.warning("Completa todos los n√∫meros de tr√°fico antes de guardar.")
        else:
            # Normaliza texto y FECHA -> string ISO (YYYY-MM-DD)
            df_to_save["Sucursal"] = df_to_save["Sucursal"].astype(str).str.strip()
            df_to_save["Tr√°fico"]  = df_to_save["Tr√°fico"].astype(str).str.strip()
            df_to_save["Fecha"]    = pd.to_datetime(fecha_global).strftime("%Y-%m-%d")

            # Renombra a las columnas reales de la tabla
            payload = (
                df_to_save[["Sucursal", "Tr√°fico", "Fecha"]]
                .rename(columns={"Tr√°fico": "Trafico"})
                .to_dict(orient="records")
            )

            # Inserta (o usa upsert si quieres evitar duplicados Sucursal+Fecha)
            res = supabase.table("viajes_distribucion").insert(payload).execute()
            # Si prefieres actualizar/enlazar:
            # res = supabase.table("viajes_distribucion") \
            #     .upsert(payload, on_conflict="Sucursal,Fecha").execute()

            st.success(f"‚úÖ Tr√°ficos guardados ({len(payload)} filas).")
    except Exception as e:
        st.error(f"Error al guardar en Supabase: {e}")

st.divider()

# ======================================================================================================
st.title("üìòCat√°logo de Distribuci√≥n por AREA/GASTO")

tipos_distribucion = [
    "Facturaci√≥n Dlls", "MC", "Tr√°ficos",
    "Empleado hub", "Empleados mv", "XTRALEASE", "Uso Cajas"
]

# Validamos que venga del M√≥dulo 1
if 'resumen' in st.session_state:
    resumen = st.session_state['resumen']
    resumen = resumen[['AREA/CUENTA']].drop_duplicates().reset_index(drop=True)

    # Cargar cat√°logo existente desde Supabase
    data_supabase = supabase.table("catalogo_distribucion").select("*").execute().data
    catalogo_existente = pd.DataFrame(data_supabase)

    # Unir resumen con cat√°logo existente
    if not catalogo_existente.empty:
        catalogo_existente = catalogo_existente.rename(columns={
            "area_cuenta": "AREA/CUENTA",
            "tipo_distribucion": "TIPO DISTRIBUCI√ìN"
        })
        resumen_merged = resumen.merge(catalogo_existente, on="AREA/CUENTA", how="left")
    else:
        resumen_merged = resumen.copy()
        resumen_merged["TIPO DISTRIBUCI√ìN"] = None

    st.subheader("Cat√°logo de Distribuci√≥n")
    resumen_merged = resumen_merged.sort_values(by=["TIPO DISTRIBUCI√ìN", "AREA/CUENTA"], na_position="first").reset_index(drop=True)
    edited_df = st.data_editor(
        resumen_merged,
        num_rows="dynamic",
        use_container_width=True,
        column_config={
            "TIPO DISTRIBUCI√ìN": st.column_config.SelectboxColumn(
                label="Tipo de Distribuci√≥n",
                options=tipos_distribucion,
                required=True
            )
        }
    )

    # Bot√≥n para guardar nuevos registros y actualizaciones en Supabase
    if st.button("üíæ Guardar en Supabase"):
        nuevos = edited_df[edited_df["TIPO DISTRIBUCI√ìN"].notna()]
        for _, row in nuevos.iterrows():
            supabase.table("catalogo_distribucion").upsert({
                "area_cuenta": row["AREA/CUENTA"],
                "tipo_distribucion": row["TIPO DISTRIBUCI√ìN"]
            }).execute()
        st.success("Cat√°logo actualizado en Supabase.")

else:
    st.warning("Primero genera el resumen de GASTO GENERAL en el M√≥dulo 1.")

# ======================================================================================================
st.title("üìäDatos Generales y C√°lculo de Porcentajes")

# Subida del archivo con la hoja GTS
archivo_gts = st.file_uploader("üì§ Sube el archivo con la hoja 'GTS'", type=["xlsx"])

if archivo_gts:
    try:
        df_gts = pd.read_excel(archivo_gts, sheet_name="GTS")

        # Limpiar encabezados
        df_gts.columns = df_gts.columns.str.strip().str.upper()

        # Mostrar tabla original
        st.subheader("üìÑ Datos GTS cargados:")
        st.dataframe(df_gts, use_container_width=True)

        # Seleccionar solo columnas num√©ricas (los tipos de distribuci√≥n)
        tipo_distrib_cols = df_gts.columns.drop("SUCURSAL")

        # Calcular totales por tipo
        totales = df_gts[tipo_distrib_cols].sum().rename("TOTAL").to_frame().T

        st.subheader("üìå Totales por Tipo de Distribuci√≥n")
        st.dataframe(totales, use_container_width=True)

        # Calcular porcentajes por sucursal y tipo
        porcentajes = df_gts.copy()
        for col in tipo_distrib_cols:
            total = df_gts[col].sum()
            if total != 0:
                porcentajes[col] = df_gts[col] / total
            else:
                porcentajes[col] = 0

        st.subheader("üìà Porcentaje de Participaci√≥n")
        st.dataframe(porcentajes, use_container_width=True)

        # Guardar en memoria para m√≥dulo 4
        st.session_state["porcentajes"] = porcentajes.set_index("SUCURSAL")

    except Exception as e:
        st.error(f"Ocurri√≥ un error al procesar la hoja GTS: {e}")

# ======================================================================================================
st.title("üîÑGasto General + Costos por Sucursal (con Tr√°fico/Fecha)")

# ---------- Comprobaci√≥n de insumos previos ----------
if not all(k in st.session_state for k in ["df_original", "resumen", "porcentajes"]):
    st.warning("Faltan datos. Completa primero los m√≥dulos previos (df_original, resumen, porcentajes).")
    st.stop()

df_original = st.session_state["df_original"].copy()
resumen_gasto_general = st.session_state["resumen"].copy()  # agrupado por AREA/CUENTA
porcentajes = st.session_state["porcentajes"].copy()

# Normalizaciones
df_original.columns = df_original.columns.str.strip().str.upper()
porcentajes.columns = [str(c).upper() for c in porcentajes.columns]
if "CONCEPTO" not in df_original.columns:
    df_original["CONCEPTO"] = ""

# --- CONFIGURACI√ìN SUPABASE ---
url = st.secrets["SUPABASE_URL"]
key = st.secrets["SUPABASE_KEY"]
supabase = create_client(url, key)

# Cat√°logo (AREA/CUENTA -> TIPO DISTRIBUCI√ìN)
cat_resp = supabase.table("catalogo_distribucion").select("*").execute()
catalogo = pd.DataFrame(cat_resp.data)
if catalogo.empty:
    st.error("No hay datos en 'catalogo_distribucion'.")
    st.stop()
catalogo = catalogo.rename(columns={
    "area_cuenta": "AREA/CUENTA",
    "tipo_distribucion": "TIPO DISTRIBUCI√ìN"
})

# Viajes/fechas (para seleccionar fecha espec√≠fica)
viajes_resp = supabase.table("viajes_distribucion").select("*").execute()
viajes = pd.DataFrame(viajes_resp.data)
if viajes.empty:
    st.info("No hay registros en 'viajes_distribucion'. Trafico/Fecha quedar√°n vac√≠os.")
    viajes = pd.DataFrame(columns=["Sucursal", "Trafico", "Fecha"])
viajes = viajes.rename(columns={"Sucursal": "SUCURSAL", "Trafico": "TRAFICO", "Fecha": "FECHA"})
viajes["SUCURSAL"] = viajes["SUCURSAL"].astype(str).str.upper().str.strip()
viajes["FECHA"] = pd.to_datetime(viajes["FECHA"], errors="coerce")

# Selector de fecha espec√≠fica (usa las disponibles en la tabla)
fechas_disponibles = sorted(viajes["FECHA"].dropna().dt.date.unique())
fecha_elegida = st.date_input(
    "üìÖ Selecciona la FECHA de viajes_distribucion a usar",
    value=(fechas_disponibles[-1] if len(fechas_disponibles) else pd.Timestamp.today().date()),
    min_value=(fechas_disponibles[0] if len(fechas_disponibles) else pd.Timestamp.today().date())
)

viajes_sel = viajes[viajes["FECHA"].dt.date.eq(fecha_elegida)].copy()
viajes_sel["FECHA"] = viajes_sel["FECHA"].dt.strftime("%Y-%m-%d")  # ISO string
viajes_sel = viajes_sel.drop_duplicates(subset=["SUCURSAL"], keep="last")

# Helper para anexar Trafico/Fecha por sucursal
def anexar_trafico_fecha(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df.assign(TRAFICO=None, FECHA=None)
    out = df.merge(viajes_sel[["SUCURSAL", "TRAFICO", "FECHA"]], on="SUCURSAL", how="left")
    return out

# ============ BLOQUE A: COSTOS CON SUCURSAL ASIGNADA ============
no_general = df_original[df_original["SUCURSAL"].str.upper().ne("GASTO GENERAL")].copy()

# TIPO COSTO fijo para este bloque
no_general["TIPO COSTO"] = "COSTO INDIRECTO"
# TIPO DISTRIBUCI√ìN fijo para este bloque
no_general["TIPO DISTRIBUCI√ìN"] = "Costo fijo en sucursal"

# Agrupar por AREA/CUENTA + SUCURSAL + TIPO DISTRIBUCI√ìN + TIPO COSTO
directos_agr = (
    no_general
    .assign(SUCURSAL=lambda d: d["SUCURSAL"].astype(str).str.upper().str.strip())
    .groupby(["AREA/CUENTA", "SUCURSAL", "TIPO DISTRIBUCI√ìN", "TIPO COSTO"], as_index=False)["CARGOS"]
    .sum()
    .rename(columns={"CARGOS": "CARGO ASIGNADO"})
)

# Anexar Trafico/Fecha por sucursal (fecha seleccionada)
directos_agr = anexar_trafico_fecha(directos_agr)

# ============ BLOQUE B: GASTO GENERAL (prorrateo) ============
gasto_general = df_original[df_original["SUCURSAL"].str.upper().eq("GASTO GENERAL")].copy()

# TIPO COSTO por regla de CONCEPTO (prefijos)
def tipo_costo_por_concepto(concepto: str) -> str:
    c = str(concepto).strip().upper()
    if c.startswith("IN"):
        return "COMUN INTERNO"
    if c.startswith("EX"):
        return "COMUN EXTERNO"
    return "COSTO INDIRECTO"

gasto_general["TIPO COSTO"] = gasto_general["CONCEPTO"].map(tipo_costo_por_concepto)

# Agrupar por AREA/CUENTA + TIPO COSTO (para preservar la etiqueta)
gg_agr = (
    gasto_general
    .groupby(["AREA/CUENTA", "TIPO COSTO"], as_index=False)["CARGOS"]
    .sum()
    .rename(columns={"CARGOS": "TOTAL_AREA"})
)

# Unir con cat√°logo para obtener TIPO DISTRIBUCI√ìN
gg_agr = gg_agr.merge(catalogo, on="AREA/CUENTA", how="left")
if gg_agr["TIPO DISTRIBUCI√ìN"].isna().any():
    faltantes = gg_agr.loc[gg_agr["TIPO DISTRIBUCI√ìN"].isna(), "AREA/CUENTA"].unique().tolist()
    st.error(f"Faltan tipos de distribuci√≥n en el cat√°logo para: {faltantes[:10]}{'...' if len(faltantes)>10 else ''}")
    st.stop()

# Expandir por sucursales seg√∫n porcentajes del tipo
prorr_rows = []
for _, r in gg_agr.iterrows():
    area = r["AREA/CUENTA"]
    tipo_dist = str(r["TIPO DISTRIBUCI√ìN"]).upper()
    tipo_costo = r["TIPO COSTO"]
    total = r["TOTAL_AREA"]

    if tipo_dist not in porcentajes.columns:
        st.warning(f"No hay porcentajes para el tipo '{tipo_dist}'. Se omite AREA/CUENTA: {area}")
        continue

    for suc, pct in porcentajes[tipo_dist].items():
        if pct and pct > 0:
            prorr_rows.append({
                "AREA/CUENTA": area,
                "SUCURSAL": str(suc).upper().strip(),
                "TIPO DISTRIBUCI√ìN": r["TIPO DISTRIBUCI√ìN"],  # conservar como est√° en cat√°logo (no upper si no quieres)
                "TIPO COSTO": tipo_costo,
                "CARGO ASIGNADO": round(total * float(pct), 2)
            })

prorr_gg = pd.DataFrame(prorr_rows)
prorr_gg = anexar_trafico_fecha(prorr_gg)

# ============ RESULTADO FINAL ============
resultado = pd.concat([directos_agr, prorr_gg], ignore_index=True)

st.subheader("üìä Resultado final (con Tr√°fico/Fecha por sucursal y fecha seleccionada)")
st.dataframe(resultado, use_container_width=True)

# Guardar para m√≥dulos siguientes
st.session_state["prorrateo_completo"] = resultado

# Descargar
def to_excel_bytes(df: pd.DataFrame) -> bytes:
    from io import BytesIO
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as xw:
        df.to_excel(xw, index=False, sheet_name="Prorrateo")
    return buffer.getvalue()

st.download_button(
    "üì• Descargar prorrateo completo",
    data=to_excel_bytes(resultado),
    file_name="prorrateo_completo.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

# ======================================================================================================
st.title("üìòGenerales (Comunes separados) e Indirectos")

# --- Obtener el prorrateo completo del M√≥dulo 4 ---
key_candidates = ["prorrateo_completo", "prorrateo"]
prorr_key = next((k for k in key_candidates if k in st.session_state), None)

if prorr_key is None or "df_original" not in st.session_state:
    st.warning("Faltan datos. Aseg√∫rate de haber ejecutado el M√≥dulo 4 y tener df_original.")
    st.stop()

prorr = st.session_state[prorr_key].copy()
df_original = st.session_state["df_original"].copy()

# Normalizaci√≥n m√≠nima
for df in (prorr, df_original):
    df.columns = df.columns.str.upper()

col_suc = "SUCURSAL"
col_val = "CARGO ASIGNADO"
col_tipo = "TIPO COSTO"

# 1) Comunes por sucursal (ya vienen con nombres finales)
comunes = prorr[prorr[col_tipo].isin(["COMUN INTERNO", "COMUN EXTERNO"])]

pivot_comunes = (
    comunes.pivot_table(
        index=col_suc,
        columns=col_tipo,
        values=col_val,
        aggfunc="sum",
        fill_value=0.0,
    )
    .reset_index()
)

for expected in ["COMUN INTERNO", "COMUN EXTERNO"]:
    if expected not in pivot_comunes.columns:
        pivot_comunes[expected] = 0.0

st.subheader("üìå Comunes por sucursal")
st.dataframe(pivot_comunes[[col_suc, "COMUN INTERNO", "COMUN EXTERNO"]], use_container_width=True)

# ---------- 2) Indirectos por sucursal ----------
# Suma todo lo etiquetado como COSTO INDIRECTO (incluye directos y Gasto General cuyo concepto no inicia IN/EX)
indirectos = (
    prorr[prorr[col_tipo] == "COSTO INDIRECTO"]
    .groupby(col_suc, as_index=False)[col_val]
    .sum()
    .rename(columns={col_val: "INDIRECTO"})
)

st.subheader("üìå Indirectos por sucursal")
st.dataframe(indirectos, use_container_width=True)

# ---------- 3) Consolidado: comunes separados + indirecto + total ----------
final = (
    pivot_comunes.merge(indirectos, on=col_suc, how="outer")
    .fillna(0.0)
)

final["TOTAL"] = final["COMUN INTERNO"] + final["COMUN EXTERNO"] + final["INDIRECTO"]

st.subheader("üìä Consolidado final")
st.dataframe(final[[col_suc, "COMUN INTERNO", "COMUN EXTERNO", "INDIRECTO", "TOTAL"]],
             use_container_width=True)

# ---------- 4) Exportar a Excel ----------
def exportar_excel():
    from io import BytesIO
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        pivot_comunes[[col_suc, "COMUN INTERNO", "COMUN EXTERNO"]].to_excel(
            writer, sheet_name="Generales", index=False
        )
        indirectos.to_excel(writer, sheet_name="Indirectos", index=False)
        final[[col_suc, "COMUN INTERNO", "COMUN EXTERNO", "INDIRECTO", "TOTAL"]].to_excel(
            writer, sheet_name="Consolidado", index=False
        )
    return buffer.getvalue()

st.download_button(
    "üì• Descargar Excel (Generales/Indirectos/Consolidado)",
    data=exportar_excel(),
    file_name="generales_indirectos_consolidado.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)
